{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43d0d487",
   "metadata": {},
   "source": [
    "## Micro Domain\n",
    "\n",
    "The micro domain is defined by a bounding box and a smooth function parameterising the floor of the micro domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce68e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/emastr/phd/')\n",
    "\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import torch.autograd as agrad\n",
    "import matplotlib.pyplot as plt\n",
    "from util.plot_tools import *\n",
    "from architecture.ufno_1d import *\n",
    "from boundary_solvers.blobs import *\n",
    "from boundary_solvers.geometry import *\n",
    "from scipy.sparse.linalg import LinearOperator #, gmres\n",
    "from operators.stokes_operator import StokesAdjointBoundaryOp\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c562a",
   "metadata": {},
   "source": [
    "## Create data loader\n",
    "\n",
    "Load and transform the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c70f7eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_data(data):\n",
    "    xlabels = ['x', 'y', 'dx', 'dy', 'ddx', 'ddy', 'vx', 'vy', 'w', 't']\n",
    "    ylabels = ['rx', 'ry']\n",
    "    inp = {xlabels[i]: data['X'][:, i, :] for i in range(10)}\n",
    "    out = {ylabels[i]: data['Y'][:, i, :] for i in range(2)}\n",
    "    return (inp, out)\n",
    "\n",
    "def unpack(transform):\n",
    "    \"\"\"Decorator for if a method is supposed to act on the values of a dict.\"\"\"\n",
    "    def up_transform(data, *args, **kwargs):\n",
    "        if type(data) == dict:\n",
    "            return {k: transform(data[k], *args, **kwargs) for k in data.keys()}\n",
    "        else:\n",
    "            return transform(data, *args, **kwargs)\n",
    "    return up_transform\n",
    "\n",
    "@unpack\n",
    "def subsample(x, idx):\n",
    "    return x[idx]\n",
    "\n",
    "@unpack\n",
    "def integrate(x, w):\n",
    "    return torch.cumsum(x * w, axis=len(x.shape)-1)\n",
    "\n",
    "def subdict(dic, keys):\n",
    "    return {k: dic[k] for k in keys if k in dic.keys()}\n",
    "\n",
    "def concat_dict_entries(data):\n",
    "    return torch.cat(tuple((d[:, None, :] for d in data.values())), dim=1)\n",
    "    \n",
    "def arclength(dx, dy, w):\n",
    "    return integrate((dx**2 + dy**2)**0.5, w)    \n",
    "\n",
    "def normalize(dx, dy):\n",
    "    \"\"\"Normalize 2-dim vector\"\"\"\n",
    "    mag = (dx**2 + dy**2)**0.5\n",
    "    return dx/mag, dy/mag\n",
    "    \n",
    "def curvature(dx, dy, ddx, ddy):\n",
    "    \"\"\"Find curvature of line segment given points\"\"\"\n",
    "    mag = (dx**2 + dy**2)**0.5\n",
    "    return (dx * ddy - dy * ddx) / (mag ** 3)\n",
    "\n",
    "def invariant_quantities(inp):\n",
    "    labels = ('tx', 'ty', 'c')\n",
    "    tx, ty = normalize(inp['dx'], inp['dy'])\n",
    "    c = curvature(inp['dx'], inp['dy'], inp['ddx'], inp['ddy'])\n",
    "    data = (tx, ty, c)\n",
    "    return {labels[i]: data[i] for i in range(len(data))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b638a9e",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7c0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "@unpack\n",
    "def to_dtype(tensor, dtype):\n",
    "    return tensor.to(dtype)\n",
    "\n",
    "# Load and transform\n",
    "data = torch.load(f\"/home/emastr/phd/data/problem_data_riesz_TEST.torch\")\n",
    "inp, out = unpack_data(data)\n",
    "\n",
    "    \n",
    "dtype = torch.double\n",
    "inp, out = to_dtype(inp, dtype), to_dtype(out, dtype)\n",
    "\n",
    "# Add invariant quantities to data.\n",
    "inp.update(invariant_quantities(inp))\n",
    "\n",
    "# Normalise curvature using monotone function sigmoid(x/2) - 1/2.\n",
    "inp['c'] = 1/(1 + torch.exp(-0.5 * inp['c'])) - 0.5 \n",
    "\n",
    "# REMOVE OUTLIERS:\n",
    "if True:\n",
    "    N = inp[\"x\"].shape[0]\n",
    "    outliers = [ 369,  670, 1005,  382,  925, 1399,  379,  387,  732,  910,   28, 1333, 168, 1197,  113]\n",
    "    non_outl = [n for n in range(N) if n not in outliers]\n",
    "    inp = subsample(inp, non_outl)\n",
    "    out = subsample(out, non_outl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427292f9",
   "metadata": {},
   "source": [
    "Split into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1600c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard features (coordinates, derivatives of parameterisation)\n",
    "features = ['x', 'y', 'dx','dy','ddx','ddy','vx','vy']\n",
    "\n",
    "# Invariant features (coordinates, tangent, curvature)\n",
    "features = ['x', 'y', 'tx', 'ty', 'c', 'vx', 'vy']\n",
    "\n",
    "# Reduced features (trust fourier transform to handle the rest)\n",
    "#features = {'x', 'y', 'vx', 'vy'}\n",
    "\n",
    "\n",
    "## TRAINING DATA\n",
    "\n",
    "M_train = 1500#0\n",
    "M_batch = 20 # Batch\n",
    "idx_train = list(range(M_train))\n",
    "dat_train = subsample(inp, idx_train)\n",
    "X_train = concat_dict_entries(subdict(dat_train, features))\n",
    "V_train = concat_dict_entries(subdict(subsample(inp, idx_train), ['vx', 'vy']))\n",
    "Y_train = concat_dict_entries(subsample(out, idx_train))\n",
    "#X_train = subdict(X_train, {'vx', 'vy'})\n",
    "\n",
    "## TEST DATA\n",
    "M_test = 100#0\n",
    "idx_test = list(range(M_train, M_test + M_train))\n",
    "dat_test = subsample(inp, idx_test)\n",
    "X_test = concat_dict_entries(subdict(dat_test, features))\n",
    "V_test = concat_dict_entries(subdict(subsample(inp, idx_test),['vx', 'vy']))\n",
    "Y_test = concat_dict_entries(subsample(out, idx_test))\n",
    "#X_test = subdict(X_test, {'vx', 'vy'})\n",
    "\n",
    "in_channels = len(features)\n",
    "out_channels = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88975206",
   "metadata": {},
   "source": [
    "Create network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece85a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\"modes\": 10,\n",
    "            \"input_features\": features,\n",
    "            \"weight_decay\": 0.0000000,\n",
    "            \"depth\": 3,\n",
    "            \"width\": 2\n",
    "            \"kwargs\": {\"layer_widths\": [2*len(features),]*2}}\n",
    "\n",
    "net = UFNO1d(in_channels=in_channels, \n",
    "           min_out_channels = settings[\"width\"] * in_channels,\n",
    "           out_channels=out_channels, \n",
    "           depth = settings[\"depth\"],\n",
    "           modes=settings[\"modes\"],\n",
    "            **settings[\"kwargs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c30a9f",
   "metadata": {},
   "source": [
    "Do training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b0793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefine list of losses \n",
    "trainloss = []\n",
    "testloss  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd042652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50000. Train loss = 8.805369068625778e-07, test loss = 3.0970545400497e-06, benchmark=0.0237714855767292999\r"
     ]
    }
   ],
   "source": [
    "# Loss function\n",
    "loss_fcn  = nn.MSELoss()#L1Loss()\n",
    "loss_save = nn.MSELoss()\n",
    "benchloss = loss_fcn(V_test, Y_test).item()\n",
    "optim     = torch.optim.Adam(net.parameters(), weight_decay=settings[\"weight_decay\"])\n",
    "\n",
    "# DO TRAINING LOOP \n",
    "##################################################\n",
    "N = 80001 #30001\n",
    "for i in range(N):\n",
    "    idx_batch = torch.randperm(M_train)[:M_batch] \n",
    "    Y_batch   = Y_train[idx_batch]\n",
    "    X_batch   = X_train[idx_batch]\n",
    "    \n",
    "    # Train on truncated net that expands as iterations progress\n",
    "    loss = loss_fcn(net(X_batch), Y_batch)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "        \n",
    "    trainloss.append(loss.item())\n",
    "    testloss.append(loss_save(net(X_test), Y_test).item())\n",
    "        \n",
    "    optim.zero_grad()\n",
    "        \n",
    "    print(f\"Step {i}. Train loss = {trainloss[-1]}, test loss = {testloss[-1]}, benchmark={benchloss}\", end=\"\\r\")\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        torch.save({\"state dict\" : net.state_dict(), \n",
    "                    \"settings\"   : settings,\n",
    "                    \"trainloss\"  : trainloss,\n",
    "                    \"testloss\"   : testloss}, \n",
    "                    f\"/home/emastr/phd/data/runs/ufno_2_{i+50000}.Torch\") # old namme unet_state_dict #Kernel size 5, stride 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08097667",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = torch.load(f\"/home/emastr/phd/data/ufno_{30000}.Torch\")\n",
    "#save = torch.load(f\"/home/emastr/phd/data/fno_adjoint_state_dict_2022_12_02_default25_{30000}.Torch\")\n",
    "\n",
    "trainloss = save[\"trainloss\"]\n",
    "testloss = save[\"testloss\"]\n",
    "net.load_state_dict(save[\"state dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ce8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_net = net(X_test)\n",
    "Y_net = Y_net.detach()\n",
    "for i in [21]:\n",
    "    plt.figure(1)\n",
    "    plt.plot(V_test[i, 0, :], label='inpx')\n",
    "    plt.plot(Y_net[i, 0, :], label='netx')\n",
    "    plt.plot(Y_test[i, 0, :], '--', label='outx')\n",
    "    plt.legend()\n",
    "    plt.figure(2)\n",
    "    plt.plot(V_test[i, 1, :])\n",
    "    plt.plot(Y_net[i, 1, :])\n",
    "    plt.plot(Y_test[i, 1, :])\n",
    "    \n",
    "plt.figure(3)\n",
    "plt.semilogy(np.linspace(0,1,len(trainloss)), trainloss)\n",
    "plt.semilogy(np.linspace(0,1,len(testloss)), testloss)\n",
    "\n",
    "plt.figure(4)\n",
    "plt.plot(inp['x'][0, :], inp['y'][0, :])\n",
    "plt.quiver(inp['x'][0,:], inp['y'][0,:], inp['dy'][0,:], -inp['dx'][0,:])\n",
    "plt.quiver(inp['x'][0,:], inp['y'][0,:], inp['ddx'][0,:], inp['ddy'][0,:], color='red')\n",
    "plt.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fee59a",
   "metadata": {},
   "source": [
    "Compare to GMRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324013d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import gmres\n",
    "\n",
    "# Create a forward operator\n",
    "def op_factory(inp):\n",
    "    Z   = inp['x']   + 1j * inp['y']\n",
    "    dZ  = inp['dx']  + 1j * inp['dy']\n",
    "    ddZ = inp['ddx'] + 1j * inp['ddy']\n",
    "    W = inp['w']\n",
    "    a = torch.ones(Z.shape[0],) * 0.5 * 1j\n",
    "    return StokesAdjointBoundaryOp(Z, dZ, ddZ, W, a)\n",
    "\n",
    "op_test = op_factory(dat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ff76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.gmres import gmres\n",
    "from torch import tensordot as dot\n",
    "from torch.linalg import vector_norm as norm\n",
    "\n",
    "class gmresNet(nn.Module):\n",
    "    def __init__(self, steps, callback=None, verbose=False):\n",
    "        super().__init__()\n",
    "        self.steps = steps\n",
    "        self.callback = callback\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        \n",
    "    def forward(self, x, ops):\n",
    "        y = torch.zeros_like(x)\n",
    "        for n in range(x.shape[0]):\n",
    "            y[n, :] = gmres(lambda x: ops(x, n), x[None, n, :], \n",
    "                            steps=self.steps, \n",
    "                            callback=self.callback, \n",
    "                            verbose=self.verbose)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5fdea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(V_test.shape)\n",
    "#ops = [lambda x: torch.cat([op_test(x[r].view(1, C, M), idx=[n]).view(1, C*M) \n",
    "                            #for r in range(x.shape[0])], dim=0) for n in range(N)]\n",
    "# x is shape (C, M) -> \n",
    "ops =[]\n",
    "K = op_test.K\n",
    "(N, C, M) = V_test.shape\n",
    "\n",
    "op = lambda x, n: x + dot(x.view(x.shape[0], C, M), K[n, :, :, :, :], [[1,2],[1,3]]).view(x.shape[0], C*M)\n",
    "\n",
    "vlist =[op(Y_test[None, n].view(1, C*M), n) for n in range(N)]  \n",
    "V_view = torch.cat(vlist, dim=0)\n",
    "V_view = V_test.view(N, C*M)\n",
    "            \n",
    "#n2 = 10\n",
    "#print(f\"{norm(ops[n](Y_test[None, 11].view(1, C*M)).view(1, C, M) - V_test[None, 11])},{n}\")\n",
    "#callback = lambda *args: print(f\"{norm(opnx(Y_test[None, n2].view(1, C*M),n2).view(1, C, M) - V_test[None, n2]):.2e}\")\n",
    "\n",
    "resnet = gmresNet(steps=20)\n",
    "Y_gmres = resnet(V_view, op).view(N,C,M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d994bd",
   "metadata": {},
   "source": [
    "We find corrupt data points by checking for outliers in the training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93359c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = (net(X_train) - Y_train).detach()\n",
    "err = err.reshape(err.shape[0], err.shape[1]*err.shape[2])\n",
    "err = torch.linalg.vector_norm(err, dim=1)\n",
    "idx = torch.argsort(err, descending=True)\n",
    "\n",
    "n = idx[0]\n",
    "Y_net = net(X_train).detach()\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(Y_train[n, 0, :], '--', label=\"True\")\n",
    "plt.plot(Y_net[n, 0, :], label=\"Net\")\n",
    "plt.plot(V_train[n, 0, :], '--', label=\"Input\")\n",
    "#plt.plot(X_train[n, 3, :], '--', label=\"Input\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X_train[n,0,:], X_train[n,1,:])\n",
    "\n",
    "\n",
    "outliers = idx[0:15]\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "t_net = time.time()\n",
    "Y_net = net(X_test).detach()\n",
    "t_net = time.time() - t_net\n",
    "\n",
    "opY = op(Y_test[None, n].view(1, C*M).repeat(2,1), n).view(2, C, M)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(Y_gmres[n, 0, :], label='GMRES')\n",
    "plt.plot(Y_test[n, 0, :], '--', label=\"True\")\n",
    "plt.plot(Y_net[n, 0, :], label=\"Net\")\n",
    "plt.plot(opY[0, 0, :], label=\"OP(True)\")\n",
    "plt.plot(V_test[n, 0, :], '--', label=\"Input\")\n",
    "plt.plot(V_view.view(N, C, M)[n,0,:], label='view')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3d45aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = list(range(2, 23, 3))\n",
    "times = []\n",
    "error = []\n",
    "error2 = []\n",
    "\n",
    "for i in iters:\n",
    "    resnet = gmresNet(steps=i)\n",
    "    \n",
    "    t = time.time()\n",
    "    Y_gmres = resnet(V_view, op).view(N,C,M)\n",
    "    times.append(time.time() - t)\n",
    "    \n",
    "    Y_gmresNet = Y_net + resnet(V_view - op_test(Y_net).reshape(N, C*M), op).view(N, C, M)\n",
    "    error.append(np.array([norm(Y_test[n] - Y_gmres[n])/torch.numel(Y_test[n])**0.5 for n in range(N)]))\n",
    "    \n",
    "    error2.append(np.array([norm(Y_test[n] - Y_gmresNet[n])/torch.numel(Y_test[n])**0.5 for n in range(N)]))\n",
    "    \n",
    "error3 = np.array([norm(Y_test[n] - Y_net[n])/torch.numel(Y_test[n])**0.5 for n in range(N)])\n",
    "\n",
    "\n",
    "error_mean = [np.mean(e) for e in error]\n",
    "error2_mean = [np.mean(e) for e in error2]\n",
    "error3_mean = np.mean(error3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165290be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "for i in range(0, len(iters), 2):\n",
    "    plt.subplot(121)\n",
    "    plt.hist(np.log10(error[i]), label=f'GMRES {iters[i]} iter', alpha=0.3)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.hist(np.log10(error2[i]), label=f'GMRES {iters[i]} iter', alpha=0.3)\n",
    "    \n",
    "plt.subplot(121)\n",
    "plt.xlim([-9, 0])\n",
    "plt.xlabel(\"log(norm(error))\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"GMRES\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(np.log10(error3), label=\"FNO\", color='black', alpha=0.5)\n",
    "plt.xlim([-9, 0])\n",
    "plt.xlabel(\"log(norm(error))\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"FNO started GMRES\")\n",
    "plt.legend()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8bf637",
   "metadata": {},
   "source": [
    "Below, we compare a naive implementation of GMRES (no FMM involved), to FNO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(times, error_mean, label=\"GMRES\")\n",
    "plt.scatter([t+t_net for t in times], error2_mean, label=\"GMRES on net res\")\n",
    "for i in range(len(times)):\n",
    "    txt = f\"{iters[i]}\"\n",
    "    if i == 0:\n",
    "        txt = \"GMRES iter \" + txt\n",
    "    plt.text(times[i]*0.8, error_mean[i], txt)\n",
    "plt.scatter([t_net], [error3_mean], label=\"FNO\")\n",
    "plt.plot([t_net] + times, np.ones(len(times)+1)*error3_mean, '--', color='black', linewidth=1)\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(f\"Computation time for N={N}, M={M}\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Cost Benefit of GMRES vs FNO\")\n",
    "plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f82d5",
   "metadata": {},
   "source": [
    "## Investigate intermediate layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def forward(net, x, layer):\n",
    "        \n",
    "        # Project to FNO width\n",
    "        x = net.inp(x.permute(0,2,1)).permute(0,2,1)\n",
    "        \n",
    "        # Evaluate FNO\n",
    "        for i in range(layer):\n",
    "            y = net.conv_list[i](x) + net.lin_list[i](x)\n",
    "            x = F.gelu(y + net.loc_list[i](y))\n",
    "        \n",
    "        # Project to out_channels width\n",
    "        return x\n",
    "\n",
    "Y_net_out = forward(net, X_test, 2).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "plt.figure(figsize=(15,15))\n",
    "for j in range(3):\n",
    "    for i in range(Y_net_out.shape[1]):\n",
    "        plt.subplot(n,n,i+1)\n",
    "        plt.plot(Y_net_out[j, i, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63f3a39",
   "metadata": {},
   "source": [
    "### Visualising Convolution Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc4e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.conv_list[0].weights1.shape)\n",
    "#R = np.abs(net.conv_list[0].weights1.detach().numpy())\n",
    "R = torch.fft.irfft(net.conv_list[0].weights1, n=256).detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "N = 3\n",
    "M = 3\n",
    "K = 1\n",
    "for n in range(N):\n",
    "    for m in range(M):\n",
    "        plt.subplot(N, M, K)\n",
    "        plt.plot(R[n,m,:])\n",
    "        K += 1\n",
    "        #remove_axes(plt.gca())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Physics Informed Machine Learning Environment",
   "language": "python",
   "name": "pimlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
